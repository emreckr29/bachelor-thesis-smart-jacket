{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903227ed-0dbc-474a-8787-6fea6227bc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/envs/python313/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python313/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python313/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/envs/python313/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python313/lib/python3.13/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in /opt/conda/envs/python313/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: pyquaternion in /opt/conda/envs/python313/lib/python3.13/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/python313/lib/python3.1/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/python313/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python313/lib/python3.1/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/python313/lib/python3.1/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/envs/python313/lib/python3.1/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/python313/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/python313/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python313/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python313/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/conda/envs/python313/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/envs/python313/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /opt/conda/envs/python313/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/conda/envs/python313/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/python313/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/python313/lib/python3.1/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/python313/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas scikit-learn tensorflow matplotlib seaborn pyquaternion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782c3e32-a3e5-4a1c-b371-aca413b83086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:01:22.269613: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-27 19:01:22.270023: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-27 19:01:22.337662: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-27 19:01:23.642677: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-27 19:01:23.644247: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adım 2: Veri Yükleme ve Ön İşleme Başladı...\n",
      "Toplam 300 adet .pkl kaydı yüklendi.\n",
      "Adım 3: Tüm veriler 80 adımına eşitleniyor...\n",
      "Boyut Eşitleme Tamamlandı.\n",
      "\n",
      "Adım 4: Veriyi Derin Öğrenme Formatına Dönüştürme Başladı...\n",
      "Bulunan sınıflar (4 adet): ['LeaningBodyBack' 'TooHighFlexion' 'True' 'UnstableShoulder']\n",
      "Veri şekli (X): (300, 80, 40)\n",
      "Etiket şekli (y): (300, 4)\n",
      "Veri Dönüştürme Tamamlandı.\n",
      "\n",
      "Adım 5: Veriyi Ayırma ve Ölçekleme Başladı...\n",
      "Eğitim verisi: (240, 80, 40), Test verisi: (60, 80, 40)\n",
      "Veri Ayırma ve Ölçekleme Tamamlandı.\n",
      "\n",
      "Adım 6: LSTM Modeli Oluşturuluyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:01:27.610558: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m26,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,868</span> (159.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,868\u001b[0m (159.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,676</span> (158.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,676\u001b[0m (158.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Oluşturma Tamamlandı.\n",
      "\n",
      "Adım 7: Model Eğitimi Başlıyor...\n",
      "Epoch 1/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.3917 - loss: 1.4633 - val_accuracy: 0.5500 - val_loss: 1.3077\n",
      "Epoch 2/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 1.1279 - val_accuracy: 0.7000 - val_loss: 1.2240\n",
      "Epoch 3/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6917 - loss: 0.8453 - val_accuracy: 0.7500 - val_loss: 1.1136\n",
      "Epoch 4/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8292 - loss: 0.5562 - val_accuracy: 0.7833 - val_loss: 0.9553\n",
      "Epoch 5/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8625 - loss: 0.4766 - val_accuracy: 0.9000 - val_loss: 0.7953\n",
      "Epoch 6/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9333 - loss: 0.3053 - val_accuracy: 0.8667 - val_loss: 0.6485\n",
      "Epoch 7/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9375 - loss: 0.2412 - val_accuracy: 0.9667 - val_loss: 0.4431\n",
      "Epoch 8/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9625 - loss: 0.1726 - val_accuracy: 0.9500 - val_loss: 0.3077\n",
      "Epoch 9/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9708 - loss: 0.1536 - val_accuracy: 0.9833 - val_loss: 0.2064\n",
      "Epoch 10/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9875 - loss: 0.1072 - val_accuracy: 0.9833 - val_loss: 0.1540\n",
      "Epoch 11/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9833 - loss: 0.1029 - val_accuracy: 1.0000 - val_loss: 0.0989\n",
      "Epoch 12/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9833 - loss: 0.0712 - val_accuracy: 1.0000 - val_loss: 0.0702\n",
      "Epoch 13/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 0.9667 - val_loss: 0.0906\n",
      "Epoch 14/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 1.0000 - val_loss: 0.0505\n",
      "Epoch 15/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0343 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
      "Epoch 16/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9917 - loss: 0.0420 - val_accuracy: 1.0000 - val_loss: 0.0198\n",
      "Epoch 17/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9958 - loss: 0.0392 - val_accuracy: 1.0000 - val_loss: 0.0146\n",
      "Epoch 18/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9875 - loss: 0.0380 - val_accuracy: 0.9833 - val_loss: 0.1000\n",
      "Epoch 19/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9958 - loss: 0.0307 - val_accuracy: 0.9833 - val_loss: 0.0410\n",
      "Epoch 20/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.9833 - val_loss: 0.0409\n",
      "Epoch 21/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9958 - loss: 0.0233 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
      "Epoch 22/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.9833 - val_loss: 0.0297\n",
      "Epoch 23/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.9833 - val_loss: 0.0513\n",
      "Epoch 24/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9833 - val_loss: 0.0589\n",
      "Epoch 25/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.9833 - val_loss: 0.0151\n",
      "Epoch 26/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9833 - val_loss: 0.0176\n",
      "Epoch 27/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9833 - val_loss: 0.0194\n",
      "Epoch 28/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9667 - val_loss: 0.0348\n",
      "Epoch 29/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9958 - loss: 0.0213 - val_accuracy: 0.9667 - val_loss: 0.0657\n",
      "Epoch 30/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9833 - val_loss: 0.0187\n",
      "Epoch 31/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 32/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9958 - loss: 0.0265 - val_accuracy: 0.9833 - val_loss: 0.0175\n",
      "Epoch 33/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9917 - loss: 0.0533 - val_accuracy: 0.9833 - val_loss: 0.0224\n",
      "Epoch 34/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.9833 - val_loss: 0.0197\n",
      "Epoch 35/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9917 - loss: 0.0192 - val_accuracy: 0.9833 - val_loss: 0.0166\n",
      "Epoch 36/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9833 - val_loss: 0.0171\n",
      "Epoch 37/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9833 - val_loss: 0.0159\n",
      "Epoch 38/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9833 - val_loss: 0.0155\n",
      "Epoch 39/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9833 - val_loss: 0.0157\n",
      "Epoch 40/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9958 - loss: 0.0086 - val_accuracy: 0.9833 - val_loss: 0.0161\n",
      "Epoch 41/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9833 - val_loss: 0.0156\n",
      "Epoch 42/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9833 - val_loss: 0.0151\n",
      "Epoch 43/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9958 - loss: 0.0111 - val_accuracy: 0.9833 - val_loss: 0.0187\n",
      "Epoch 44/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9958 - loss: 0.0090 - val_accuracy: 0.9833 - val_loss: 0.0165\n",
      "Epoch 45/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9833 - val_loss: 0.0142\n",
      "Epoch 46/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9833 - val_loss: 0.0134\n",
      "Epoch 47/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9833 - val_loss: 0.0138\n",
      "Epoch 48/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9833 - val_loss: 0.0146\n",
      "Epoch 49/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9833 - val_loss: 0.0155\n",
      "Epoch 50/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9833 - val_loss: 0.0160\n",
      "Epoch 51/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9833 - val_loss: 0.0169\n",
      "Epoch 52/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9833 - val_loss: 0.0182\n",
      "Epoch 53/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9833 - val_loss: 0.0209\n",
      "Epoch 54/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9833 - val_loss: 0.0218\n",
      "Epoch 55/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9833 - val_loss: 0.0221\n",
      "Epoch 56/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9833 - val_loss: 0.0222\n",
      "Epoch 57/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9833 - val_loss: 0.0225\n",
      "Epoch 58/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9833 - val_loss: 0.0226\n",
      "Epoch 59/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9833 - val_loss: 0.0226\n",
      "Epoch 60/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9833 - val_loss: 0.0228\n",
      "Model Eğitimi Tamamlandı.\n",
      "\n",
      "Adım 8: Model Değerlendirmesi...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9833 - loss: 0.0228\n",
      "Test Accuracy: 98.33%\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " LeaningBodyBack       0.94      1.00      0.97        15\n",
      "  TooHighFlexion       1.00      0.93      0.97        15\n",
      "            True       1.00      1.00      1.00        15\n",
      "UnstableShoulder       1.00      1.00      1.00        15\n",
      "\n",
      "        accuracy                           0.98        60\n",
      "       macro avg       0.98      0.98      0.98        60\n",
      "    weighted avg       0.98      0.98      0.98        60\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adım 9: Model ve diğer nesneler kaydediliyor...\n",
      "Tüm dosyalar başarıyla 'final_lstm_models_' klasörüne kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Adım 1: Gerekli Kütüphaneleri Yükleme\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pyquaternion import Quaternion # Normalizasyon için\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- KONFİGÜRASYON ---\n",
    "# Verinin bulunduğu ana klasör\n",
    "DATA_FOLDER = '' \n",
    "# Hangi hareketi eğitmek istiyoruz?\n",
    "MOVEMENT_TYPE = ''\n",
    "# Tüm zaman serilerini eşitleyeceğimiz uzunluk (gördüğümüz 80-82'ye göre 80 ideal)\n",
    "TIMESTEPS = 80\n",
    "NUM_SENSORS = 10\n",
    "FEATURES_PER_SENSOR = 4 # w, x, y, z\n",
    "FEATURES = NUM_SENSORS * FEATURES_PER_SENSOR # Toplam 40 özellik\n",
    "USERS_TO_ANALYZE = [\"User-A\",\"User-B\",\"User-C\", \"User-D\", \"User-E\"]\n",
    "\n",
    "\n",
    "# --- Adım 2.1: Normalizasyon için Yardımcı Fonksiyon ---\n",
    "\n",
    "def normalize_sequence(sequence_data):\n",
    "    \"\"\"\n",
    "    (N, 40) şeklindeki bir NumPy dizisini ilk karesine göre normalize eder.\n",
    "    Sıralamanın (w, x, y, z) olduğunu varsayar.\n",
    "    \"\"\"\n",
    "    if not sequence_data.any(): # Tamamen sıfırsa dokunma\n",
    "        return sequence_data\n",
    "    \n",
    "    # 1. İlk kareyi (referans yönelimi) al\n",
    "    first_frame = sequence_data[0] # (40,) şeklinde\n",
    "    inverse_references = []\n",
    "    \n",
    "    # 2. 10 sensör için de ters (inverse) quaternion'ları hesapla\n",
    "    for i in range(NUM_SENSORS):\n",
    "        offset = i * FEATURES_PER_SENSOR\n",
    "        w, x, y, z = first_frame[offset], first_frame[offset+1], first_frame[offset+2], first_frame[offset+3]\n",
    "        \n",
    "        # Olası bir sıfır veriye karşı koruma\n",
    "        if w == 0 and x == 0 and y == 0 and z == 0:\n",
    "             q_ref = Quaternion(1, 0, 0, 0) # Nötr (identity) quaternion\n",
    "        else:\n",
    "            q_ref = Quaternion(w, x, y, z)\n",
    "            \n",
    "        inverse_references.append(q_ref.inverse)\n",
    "        \n",
    "    normalized_sequence = []\n",
    "    \n",
    "    # 3. Tüm zaman adımlarını (timesteps) bu referanslara göre normalize et\n",
    "    for frame in sequence_data:\n",
    "        normalized_frame_features = []\n",
    "        for i in range(NUM_SENSORS):\n",
    "            offset = i * FEATURES_PER_SENSOR\n",
    "            w, x, y, z = frame[offset], frame[offset+1], frame[offset+2], frame[offset+3]\n",
    "            \n",
    "            if w == 0 and x == 0 and y == 0 and z == 0:\n",
    "                q_live = Quaternion(1, 0, 0, 0)\n",
    "            else:\n",
    "                q_live = Quaternion(w, x, y, z)\n",
    "            \n",
    "            # Referans yönelimi çıkar\n",
    "            q_normalized = inverse_references[i] * q_live\n",
    "            \n",
    "            # Yeni (w,x,y,z) değerlerini düz listeye ekle\n",
    "            normalized_frame_features.extend([q_normalized.w, q_normalized.x, q_normalized.y, q_normalized.z])\n",
    "        \n",
    "        normalized_sequence.append(normalized_frame_features)\n",
    "        \n",
    "    return np.array(normalized_sequence)\n",
    "\n",
    "\n",
    "# --- Adım 2: Veriyi Yükleme ve Ön İşleme ---\n",
    "print(\"Adım 2: Veri Yükleme ve Ön İşleme Başladı...\")\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "movement_path = os.path.join(DATA_FOLDER, MOVEMENT_TYPE)\n",
    "# User-A, User-B, ... klasörlerinde gezin\n",
    "for user_folder in USERS_TO_ANALYZE:\n",
    "    user_path = os.path.join(movement_path, user_folder)\n",
    "    if os.path.isdir(user_path) and user_folder.startswith('User-'):\n",
    "\n",
    "        # True, WrongElbow, ... klasörlerinde gezin\n",
    "        for label_folder in os.listdir(user_path):\n",
    "            label_path = os.path.join(user_path, label_folder)\n",
    "            if os.path.isdir(label_path):\n",
    "\n",
    "                # .pkl dosyalarını oku\n",
    "                for pkl_file in os.listdir(label_path):\n",
    "                    if pkl_file.endswith('.pkl'):\n",
    "                        file_path = os.path.join(label_path, pkl_file)\n",
    "\n",
    "                        try:\n",
    "                            with open(file_path, 'rb') as f:\n",
    "                                obj = pickle.load(f)\n",
    "\n",
    "                            # .pkl içindeki 'data' anahtarından veriyi al\n",
    "                            recording_data = np.array(obj['data'])\n",
    "\n",
    "                            # Veri geçerli mi diye kontrol et (en az 1 frame olmalı)\n",
    "                            if recording_data.shape[0] < 1 or recording_data.shape[1] != FEATURES:\n",
    "                                print(f\"Uyarı: Hatalı veri atlanıyor (şekil {recording_data.shape}): {file_path}\")\n",
    "                                continue\n",
    "\n",
    "                            # --- YENİ: Normalizasyon ---\n",
    "                            recording_data_normalized = normalize_sequence(recording_data)\n",
    "\n",
    "                            all_data.append(recording_data_normalized)\n",
    "                            all_labels.append(label_folder) # Etiket olarak klasör adını kullan\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"Hata: {file_path} dosyası okunurken hata oluştu: {e}\")\n",
    "\n",
    "print(f\"Toplam {len(all_data)} adet .pkl kaydı yüklendi.\")\n",
    "\n",
    "# --- Adım 3: Boyut Eşitleme (Padding/Trimming) ---\n",
    "print(f\"Adım 3: Tüm veriler {TIMESTEPS} adımına eşitleniyor...\")\n",
    "\n",
    "# Keras'ın 'pad_sequences' fonksiyonunu kullanalım. Çok daha verimli.\n",
    "# 'post' = eksik veriyi sona ekle/sondan kırp\n",
    "X_padded = pad_sequences(\n",
    "    all_data, \n",
    "    maxlen=TIMESTEPS, \n",
    "    dtype='float32', \n",
    "    padding='post', \n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "print(\"Boyut Eşitleme Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 4: Veriyi Derin Öğrenme Formatına Dönüştürme ---\n",
    "print(\"Adım 4: Veriyi Derin Öğrenme Formatına Dönüştürme Başladı...\")\n",
    "\n",
    "X = X_padded # Artık tüm verilerimiz (sample_sayısı, 80, 40) şeklinde\n",
    "y = np.array(all_labels)\n",
    "\n",
    "# Etiketleri sayısal değerlere çevir (örn: 'Correct' -> 0, 'WrongElbow' -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Sınıf sayısını al\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Bulunan sınıflar ({num_classes} adet): {label_encoder.classes_}\")\n",
    "\n",
    "# Sayısal etiketleri one-hot encoding formatına çevir\n",
    "# Örn: 3 sınıf varsa, 1 -> [0, 1, 0]\n",
    "y_one_hot = to_categorical(y_encoded, num_classes=num_classes)\n",
    "\n",
    "print(f\"Veri şekli (X): {X.shape}\")\n",
    "print(f\"Etiket şekli (y): {y_one_hot.shape}\")\n",
    "print(\"Veri Dönüştürme Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 5: Eğitim ve Test Verisi Olarak Ayırma ve Ölçekleme ---\n",
    "print(\"Adım 5: Veriyi Ayırma ve Ölçekleme Başladı...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_one_hot, \n",
    "    test_size=0.2,       # Verinin %20'sini test için ayır\n",
    "    random_state=42,     # Tekrarlanabilir sonuçlar için\n",
    "    stratify=y_one_hot   # Sınıf dağılımını koru (çok önemli)\n",
    ")\n",
    "\n",
    "# Ölçekleme (Scaling) için veriyi 2D'ye çevirmemiz gerekiyor\n",
    "# (sample_sayısı, 80, 40) -> (sample_sayısı * 80, 40)\n",
    "scaler = StandardScaler()\n",
    "X_train_reshaped = X_train.reshape(-1, FEATURES)\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "X_train_scaled_reshaped = scaler.transform(X_train_reshaped)\n",
    "X_test_scaled_reshaped = scaler.transform(X_test.reshape(-1, FEATURES))\n",
    "\n",
    "# Veriyi tekrar 3D (LSTM formatı) haline getirelim\n",
    "X_train_scaled = X_train_scaled_reshaped.reshape(X_train.shape)\n",
    "X_test_scaled = X_test_scaled_reshaped.reshape(X_test.shape)\n",
    "\n",
    "print(f\"Eğitim verisi: {X_train_scaled.shape}, Test verisi: {X_test_scaled.shape}\")\n",
    "print(\"Veri Ayırma ve Ölçekleme Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 6: LSTM Modelini Oluşturma ---\n",
    "print(\"Adım 6: LSTM Modeli Oluşturuluyor...\")\n",
    "\n",
    "model = Sequential([\n",
    "    # Input katmanı: (80, 40) şeklinde veri alacak\n",
    "    LSTM(64, input_shape=(TIMESTEPS, FEATURES), return_sequences=True),\n",
    "    BatchNormalization(), # Katmanlar arası normalizasyon, öğrenmeyi hızlandırır\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    LSTM(32, return_sequences=False), # Son LSTM katmanı, sadece son çıktıyı verir\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    \n",
    "    # Çıkış katmanı: Sınıf sayısı kadar nöron ve 'softmax' aktivasyonu\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(\"Model Oluşturma Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 7: Modeli Eğitme ---\n",
    "print(\"Adım 7: Model Eğitimi Başlıyor...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    epochs=60, # Epoch sayısını 50-100 arası deneyebilirsin\n",
    "    batch_size=16, \n",
    "    validation_data=(X_test_scaled, y_test)\n",
    ")\n",
    "\n",
    "print(\"Model Eğitimi Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 8: Modeli Değerlendirme ---\n",
    "print(\"Adım 8: Model Değerlendirmesi...\")\n",
    "\n",
    "# Test verisi üzerindeki loss ve accuracy değerleri\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Tahminleri yap\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1) # Olasılıklardan en yüksek sınıfı seç\n",
    "y_test_labels = np.argmax(y_test, axis=1) # One-hot'tan normal etikete dön\n",
    "\n",
    "# Sınıflandırma Raporu (Precision, Recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Karışıklık Matrisi (Confusion Matrix)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues', \n",
    "    xticklabels=label_encoder.classes_, \n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel('Tahmin Edilen (Predicted)')\n",
    "plt.ylabel('Gerçek (True)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Adım 9: Modeli ve Gerekli Nesneleri Kaydetme ---\n",
    "print(\"\\nAdım 9: Model ve diğer nesneler kaydediliyor...\")\n",
    "\n",
    "MODEL_OUTPUT_DIR = f\"final_lstm_models_{MOVEMENT_TYPE}\"\n",
    "if not os.path.exists(MODEL_OUTPUT_DIR):\n",
    "    os.makedirs(MODEL_OUTPUT_DIR)\n",
    "\n",
    "# 1. Keras modelini kaydet\n",
    "model.save(os.path.join(MODEL_OUTPUT_DIR, f'{MOVEMENT_TYPE}_lstm_model.h5'))\n",
    "\n",
    "# 2. Scaler'ı kaydet\n",
    "with open(os.path.join(MODEL_OUTPUT_DIR, f'{MOVEMENT_TYPE}_scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# 3. Label Encoder'ı kaydet\n",
    "with open(os.path.join(MODEL_OUTPUT_DIR, f'{MOVEMENT_TYPE}_label_encoder.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(f\"Tüm dosyalar başarıyla '{MODEL_OUTPUT_DIR}' klasörüne kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c5909-b77a-49ea-93a1-463f02fb345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adım 3: Veri Kullanıcılara Göre Yükleniyor...\n",
      "Kullanıcı yükleniyor: User-A\n",
      "Kullanıcı yükleniyor: User-B\n",
      "Kullanıcı yükleniyor: User-C\n",
      "Kullanıcı yükleniyor: User-D\n",
      "Kullanıcı yükleniyor: User-E\n",
      "Veri Yükleme Tamamlandı.\n",
      "\n",
      "Adım 4: Etiket Kodlayıcı Hazırlanıyor...\n",
      "Bulunan sınıflar (4 adet): ['LeaningBodyBack' 'TooHighFlexion' 'True' 'UnstableShoulder']\n",
      "\n",
      "Adım 5: LOUOCV Başlatılıyor...\n",
      "-------------------------------------------------\n",
      "TEST KULLANICISI: User-A\n",
      "-------------------------------------------------\n",
      "User-A dışarıda, 240 kayıt ile model eğitiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step\n",
      "\n",
      "User-A Test Sonuçları (Accuracy: 66.67%):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " LeaningBodyBack       0.33      0.07      0.11        15\n",
      "  TooHighFlexion       1.00      0.60      0.75        15\n",
      "            True       0.52      1.00      0.68        15\n",
      "UnstableShoulder       0.79      1.00      0.88        15\n",
      "\n",
      "        accuracy                           0.67        60\n",
      "       macro avg       0.66      0.67      0.61        60\n",
      "    weighted avg       0.66      0.67      0.61        60\n",
      "\n",
      "-------------------------------------------------\n",
      "TEST KULLANICISI: User-B\n",
      "-------------------------------------------------\n",
      "User-B dışarıda, 240 kayıt ile model eğitiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fca60777560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fca60777560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 302ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fca60777560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fca60777560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step\n",
      "\n",
      "User-B Test Sonuçları (Accuracy: 73.33%):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " LeaningBodyBack       1.00      0.93      0.97        15\n",
      "  TooHighFlexion       0.50      1.00      0.67        15\n",
      "            True       0.00      0.00      0.00        15\n",
      "UnstableShoulder       1.00      1.00      1.00        15\n",
      "\n",
      "        accuracy                           0.73        60\n",
      "       macro avg       0.62      0.73      0.66        60\n",
      "    weighted avg       0.62      0.73      0.66        60\n",
      "\n",
      "-------------------------------------------------\n",
      "TEST KULLANICISI: User-C\n",
      "-------------------------------------------------\n",
      "User-C dışarıda, 240 kayıt ile model eğitiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step\n",
      "\n",
      "User-C Test Sonuçları (Accuracy: 63.33%):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " LeaningBodyBack       0.64      0.47      0.54        15\n",
      "  TooHighFlexion       1.00      0.27      0.42        15\n",
      "            True       0.74      0.93      0.82        15\n",
      "UnstableShoulder       0.50      0.87      0.63        15\n",
      "\n",
      "        accuracy                           0.63        60\n",
      "       macro avg       0.72      0.63      0.60        60\n",
      "    weighted avg       0.72      0.63      0.60        60\n",
      "\n",
      "-------------------------------------------------\n",
      "TEST KULLANICISI: User-D\n",
      "-------------------------------------------------\n",
      "User-D dışarıda, 240 kayıt ile model eğitiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Adım 1: Gerekli Kütüphaneleri Yükleme\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pyquaternion import Quaternion # Normalizasyon için\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import copy # Scaler'ı kopyalamak için\n",
    "\n",
    "# --- KONFİGÜRASYON ---\n",
    "DATA_FOLDER = '' \n",
    "MOVEMENT_TYPE = '' # Test etmek istediğin hareket\n",
    "TIMESTEPS = 80 # Veri setindeki (80, 40) şekline göre\n",
    "NUM_SENSORS = 10\n",
    "FEATURES_PER_SENSOR = 4 # w, x, y, z\n",
    "FEATURES = NUM_SENSORS * FEATURES_PER_SENSOR\n",
    "USERS_TO_ANALYZE = [\"User-A\", \"User-B\", \"User-C\", \"User-D\", \"User-E\"] # Analiz edilecek kullanıcılar\n",
    "\n",
    "# --- Adım 2: Yardımcı Fonksiyonlar ---\n",
    "\n",
    "def normalize_sequence(sequence_data):\n",
    "    \"\"\"\n",
    "    (N, 40) şeklindeki bir NumPy dizisini ilk karesine göre normalize eder.\n",
    "    PKL verisinin (w0, x0, y0, z0, ...) sırasıyla geldiğini varsayarak.\n",
    "    \"\"\"\n",
    "    if not sequence_data.any():\n",
    "        return sequence_data\n",
    "    \n",
    "    first_frame = sequence_data[0]\n",
    "    inverse_references = []\n",
    "    \n",
    "    for i in range(NUM_SENSORS):\n",
    "        offset = i * FEATURES_PER_SENSOR\n",
    "        w, x, y, z = first_frame[offset], first_frame[offset+1], first_frame[offset+2], first_frame[offset+3]\n",
    "        \n",
    "        if w == 0 and x == 0 and y == 0 and z == 0:\n",
    "             q_ref = Quaternion(1, 0, 0, 0)\n",
    "        else:\n",
    "            q_ref = Quaternion(w, x, y, z)\n",
    "            \n",
    "        inverse_references.append(q_ref.inverse)\n",
    "        \n",
    "    normalized_sequence = []\n",
    "    \n",
    "    for frame in sequence_data:\n",
    "        normalized_frame_features = []\n",
    "        for i in range(NUM_SENSORS):\n",
    "            offset = i * FEATURES_PER_SENSOR\n",
    "            w, x, y, z = frame[offset], frame[offset+1], frame[offset+2], frame[offset+3]\n",
    "            \n",
    "            if w == 0 and x == 0 and y == 0 and z == 0:\n",
    "                q_live = Quaternion(1, 0, 0, 0)\n",
    "            else:\n",
    "                q_live = Quaternion(w, x, y, z)\n",
    "            \n",
    "            q_normalized = inverse_references[i] * q_live\n",
    "            normalized_frame_features.extend([q_normalized.w, q_normalized.x, q_normalized.y, q_normalized.z])\n",
    "        \n",
    "        normalized_sequence.append(normalized_frame_features)\n",
    "        \n",
    "    return np.array(normalized_sequence)\n",
    "\n",
    "def build_model(num_classes):\n",
    "    \"\"\"\n",
    "    Her döngüde yeniden, taze bir model oluşturmak için fonksiyon.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(TIMESTEPS, FEATURES), return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        LSTM(32, return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- Adım 3: Veriyi Kullanıcılara Göre Yükleme ---\n",
    "print(\"Adım 3: Veri Kullanıcılara Göre Yükleniyor...\")\n",
    "\n",
    "# Veriyi { 'User-A': {'data': [...], 'labels': [...]}, ... } şeklinde saklayalım\n",
    "data_by_user = {}\n",
    "all_labels_flat = [] # Tüm etiketleri toplamak için\n",
    "\n",
    "movement_path = os.path.join(DATA_FOLDER, MOVEMENT_TYPE)\n",
    "\n",
    "for user_folder in USERS_TO_ANALYZE:\n",
    "    user_path = os.path.join(movement_path, user_folder)\n",
    "    if not os.path.isdir(user_path):\n",
    "        print(f\"Uyarı: Kullanıcı klasörü atlanıyor (bulunamadı): {user_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Kullanıcı yükleniyor: {user_folder}\")\n",
    "    data_by_user[user_folder] = {'data': [], 'labels': []}\n",
    "\n",
    "    for label_folder in os.listdir(user_path):\n",
    "        label_path = os.path.join(user_path, label_folder)\n",
    "        if os.path.isdir(label_path):\n",
    "            for pkl_file in os.listdir(label_path):\n",
    "                if pkl_file.endswith('.pkl'):\n",
    "                    file_path = os.path.join(label_path, pkl_file)\n",
    "                    try:\n",
    "                        with open(file_path, 'rb') as f:\n",
    "                            obj = pickle.load(f)\n",
    "\n",
    "                        recording_data = np.array(obj['data'])\n",
    "\n",
    "                        if recording_data.shape[0] < 1 or recording_data.shape[1] != FEATURES:\n",
    "                            continue\n",
    "\n",
    "                        recording_data_normalized = normalize_sequence(recording_data)\n",
    "\n",
    "                        data_by_user[user_folder]['data'].append(recording_data_normalized)\n",
    "                        data_by_user[user_folder]['labels'].append(label_folder)\n",
    "                        all_labels_flat.append(label_folder)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Hata: {file_path} dosyası okunurken hata oluştu: {e}\")\n",
    "\n",
    "print(\"Veri Yükleme Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 4: Etiket Kodlayıcıyı (LabelEncoder) Hazırlama ---\n",
    "# LabelEncoder'ın TÜM olası etiketleri bilmesi için onu döngüden önce eğitiyoruz.\n",
    "print(\"Adım 4: Etiket Kodlayıcı Hazırlanıyor...\")\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels_flat)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Bulunan sınıflar ({num_classes} adet): {label_encoder.classes_}\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 5: Leave-One-User-Out Çapraz Doğrulama (LOUOCV) Döngüsü ---\n",
    "print(\"Adım 5: LOUOCV Başlatılıyor...\")\n",
    "\n",
    "all_scores = []\n",
    "all_reports = {}\n",
    "\n",
    "# Her bir kullanıcıyı sırayla test seti olarak ayır\n",
    "for user_to_test in USERS_TO_ANALYZE:\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    print(f\"TEST KULLANICISI: {user_to_test}\")\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    \n",
    "    # 1. Eğitim ve Test Verisini Ayır\n",
    "    X_train_raw = []\n",
    "    y_train_raw = []\n",
    "    \n",
    "    # Test verisi, dışarıda bırakılan kullanıcıdır\n",
    "    X_test_raw = data_by_user[user_to_test]['data']\n",
    "    y_test_raw = data_by_user[user_to_test]['labels']\n",
    "    \n",
    "    # Geri kalan tüm kullanıcılar eğitim verisidir\n",
    "    for user_to_train in USERS_TO_ANALYZE:\n",
    "        if user_to_train == user_to_test:\n",
    "            continue # Test kullanıcısını atla\n",
    "        X_train_raw.extend(data_by_user[user_to_train]['data'])\n",
    "        y_train_raw.extend(data_by_user[user_to_train]['labels'])\n",
    "        \n",
    "    # 2. Boyut Eşitleme (Padding/Trimming)\n",
    "    X_train = pad_sequences(X_train_raw, maxlen=TIMESTEPS, dtype='float32', padding='post', truncating='post')\n",
    "    X_test = pad_sequences(X_test_raw, maxlen=TIMESTEPS, dtype='float32', padding='post', truncating='post')\n",
    "    \n",
    "    # 3. Etiketleri Kodlama (fit etmeden, sadece transform)\n",
    "    y_train_encoded = label_encoder.transform(y_train_raw)\n",
    "    y_test_encoded = label_encoder.transform(y_test_raw)\n",
    "    \n",
    "    y_train = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "    y_test = to_categorical(y_test_encoded, num_classes=num_classes)\n",
    "\n",
    "    # 4. Ölçekleme (Scaler'ı SADECE EĞİTİM VERİSİNE GÖRE EĞİT)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_reshaped = X_train.reshape(-1, FEATURES)\n",
    "    scaler.fit(X_train_reshaped) # Sadece eğitim verisine fit et\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(-1, FEATURES)).reshape(X_test.shape)\n",
    "\n",
    "    # 5. Modeli Oluştur ve Eğit\n",
    "    print(f\"{user_to_test} dışarıda, {len(X_train)} kayıt ile model eğitiliyor...\")\n",
    "    model = build_model(num_classes)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=60, \n",
    "        batch_size=16, \n",
    "        validation_data=(X_test_scaled, y_test), # Test kullanıcısını validasyon olarak kullan\n",
    "        verbose=0 # (Eğitim loglarını gizle, sadece sonu gör)\n",
    "    )\n",
    "    \n",
    "    # 6. Modeli Değerlendir\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    all_scores.append(accuracy)\n",
    "    \n",
    "    y_pred_probs = model.predict(X_test_scaled)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    print(f\"\\n{user_to_test} Test Sonuçları (Accuracy: {accuracy*100:.2f}%):\")\n",
    "    report = classification_report(y_test_labels, y_pred, target_names=label_encoder.classes_)\n",
    "    print(report)\n",
    "    all_reports[user_to_test] = report\n",
    "\n",
    "print(\"\\n\\n--- LOUOCV GENEL SONUÇLARI ---\")\n",
    "for i, user in enumerate(USERS_TO_ANALYZE):\n",
    "    print(f\"{user} Test Doğruluğu: {all_scores[i] * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOrtalama Test Doğruluğu (Genelleme Yeteneği): {np.mean(all_scores) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33ed37-2309-4cfc-a759-36caa5eec589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 1: Gerekli Kütüphaneleri Yükleme\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pyquaternion import Quaternion # Normalizasyon için\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- KONFİGÜRASYON ---\n",
    "# Verinin bulunduğu ana klasör\n",
    "DATA_FOLDER = '' \n",
    "# Hangi hareketi eğitmek istiyoruz?\n",
    "MOVEMENT_TYPE = ''\n",
    "# Tüm zaman serilerini eşitleyeceğimiz uzunluk (gördüğümüz 80-82'ye göre 80 ideal)\n",
    "TIMESTEPS = 80\n",
    "NUM_SENSORS = 10\n",
    "FEATURES_PER_SENSOR = 4 # w, x, y, z\n",
    "FEATURES = NUM_SENSORS * FEATURES_PER_SENSOR # Toplam 40 özellik\n",
    "USERS_TO_ANALYZE = [\"User-A\",\"User-B\",\"User-C\", \"User-D\", \"User-E\"]\n",
    "\n",
    "\n",
    "# --- Adım 2.1: Normalizasyon için Yardımcı Fonksiyon ---\n",
    "\n",
    "def augment_data(sequence_data, noise_level=0.01):\n",
    "    \"\"\"Veriye rastgele küçük gürültüler (jitter) ekler.\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, sequence_data.shape)\n",
    "    return sequence_data + noise\n",
    "\n",
    "def normalize_sequence(sequence_data):\n",
    "    \"\"\"\n",
    "    (N, 40) şeklindeki bir NumPy dizisini ilk karesine göre normalize eder.\n",
    "    Sıralamanın (w, x, y, z) olduğunu varsayar.\n",
    "    \"\"\"\n",
    "    if not sequence_data.any(): # Tamamen sıfırsa dokunma\n",
    "        return sequence_data\n",
    "    \n",
    "    # 1. İlk kareyi (referans yönelimi) al\n",
    "    first_frame = sequence_data[0] # (40,) şeklinde\n",
    "    inverse_references = []\n",
    "    \n",
    "    # 2. 10 sensör için de ters (inverse) quaternion'ları hesapla\n",
    "    for i in range(NUM_SENSORS):\n",
    "        offset = i * FEATURES_PER_SENSOR\n",
    "        w, x, y, z = first_frame[offset], first_frame[offset+1], first_frame[offset+2], first_frame[offset+3]\n",
    "        \n",
    "        # Olası bir sıfır veriye karşı koruma\n",
    "        if w == 0 and x == 0 and y == 0 and z == 0:\n",
    "             q_ref = Quaternion(1, 0, 0, 0) # Nötr (identity) quaternion\n",
    "        else:\n",
    "            q_ref = Quaternion(w, x, y, z)\n",
    "            \n",
    "        inverse_references.append(q_ref.inverse)\n",
    "        \n",
    "    normalized_sequence = []\n",
    "    \n",
    "    # 3. Tüm zaman adımlarını (timesteps) bu referanslara göre normalize et\n",
    "    for frame in sequence_data:\n",
    "        normalized_frame_features = []\n",
    "        for i in range(NUM_SENSORS):\n",
    "            offset = i * FEATURES_PER_SENSOR\n",
    "            w, x, y, z = frame[offset], frame[offset+1], frame[offset+2], frame[offset+3]\n",
    "            \n",
    "            if w == 0 and x == 0 and y == 0 and z == 0:\n",
    "                q_live = Quaternion(1, 0, 0, 0)\n",
    "            else:\n",
    "                q_live = Quaternion(w, x, y, z)\n",
    "            \n",
    "            # Referans yönelimi çıkar\n",
    "            q_normalized = inverse_references[i] * q_live\n",
    "            \n",
    "            # Yeni (w,x,y,z) değerlerini düz listeye ekle\n",
    "            normalized_frame_features.extend([q_normalized.w, q_normalized.x, q_normalized.y, q_normalized.z])\n",
    "        \n",
    "        normalized_sequence.append(normalized_frame_features)\n",
    "        \n",
    "    return np.array(normalized_sequence)\n",
    "\n",
    "\n",
    "# --- Adım 2: Veriyi Yükleme ve Ön İşleme ---\n",
    "print(\"Adım 2: Veri Yükleme ve Ön İşleme Başladı...\")\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "movement_path = os.path.join(DATA_FOLDER, MOVEMENT_TYPE)\n",
    "# User-A, User-B, ... klasörlerinde gezin\n",
    "for user_folder in USERS_TO_ANALYZE:\n",
    "    user_path = os.path.join(movement_path, user_folder)\n",
    "    if os.path.isdir(user_path) and user_folder.startswith('User-'):\n",
    "\n",
    "        # True, WrongElbow, ... klasörlerinde gezin\n",
    "        for label_folder in os.listdir(user_path):\n",
    "            label_path = os.path.join(user_path, label_folder)\n",
    "            if os.path.isdir(label_path):\n",
    "\n",
    "                # .pkl dosyalarını oku\n",
    "                for pkl_file in os.listdir(label_path):\n",
    "                    if pkl_file.endswith('.pkl'):\n",
    "                        file_path = os.path.join(label_path, pkl_file)\n",
    "\n",
    "                        try:\n",
    "                            with open(file_path, 'rb') as f:\n",
    "                                obj = pickle.load(f)\n",
    "\n",
    "                            # .pkl içindeki 'data' anahtarından veriyi al\n",
    "                            recording_data = np.array(obj['data'])\n",
    "\n",
    "                            # Veri geçerli mi diye kontrol et (en az 1 frame olmalı)\n",
    "                            if recording_data.shape[0] < 1 or recording_data.shape[1] != FEATURES:\n",
    "                                print(f\"Uyarı: Hatalı veri atlanıyor (şekil {recording_data.shape}): {file_path}\")\n",
    "                                continue\n",
    "\n",
    "                            # --- YENİ: Normalizasyon ---\n",
    "                            recording_data_normalized = normalize_sequence(recording_data)\n",
    "                                \n",
    "                                # --- YENİ ADIM: Veri Artırma ---\n",
    "                                # Orijinal veriyi ekle\n",
    "                                all_data.append(recording_data_normalized)\n",
    "                                all_labels.append(label_folder)\n",
    "                                \n",
    "                                # Bir de gürültü eklenmiş (jittered) 2 kopya ekle\n",
    "                                all_data.append(augment_data(recording_data_normalized, 0.01))\n",
    "                                all_labels.append(label_folder)\n",
    "                                \n",
    "                                all_data.append(augment_data(recording_data_normalized, 0.005))\n",
    "                                all_labels.append(label_folder)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"Hata: {file_path} dosyası okunurken hata oluştu: {e}\")\n",
    "\n",
    "print(f\"Toplam {len(all_data)} adet .pkl kaydı yüklendi.\")\n",
    "\n",
    "# --- Adım 3: Boyut Eşitleme (Padding/Trimming) ---\n",
    "print(f\"Adım 3: Tüm veriler {TIMESTEPS} adımına eşitleniyor...\")\n",
    "\n",
    "# Keras'ın 'pad_sequences' fonksiyonunu kullanalım. Çok daha verimli.\n",
    "# 'post' = eksik veriyi sona ekle/sondan kırp\n",
    "X_padded = pad_sequences(\n",
    "    all_data, \n",
    "    maxlen=TIMESTEPS, \n",
    "    dtype='float32', \n",
    "    padding='post', \n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "print(\"Boyut Eşitleme Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 4: Veriyi Derin Öğrenme Formatına Dönüştürme ---\n",
    "print(\"Adım 4: Veriyi Derin Öğrenme Formatına Dönüştürme Başladı...\")\n",
    "\n",
    "X = X_padded # Artık tüm verilerimiz (sample_sayısı, 80, 40) şeklinde\n",
    "y = np.array(all_labels)\n",
    "\n",
    "# Etiketleri sayısal değerlere çevir (örn: 'Correct' -> 0, 'WrongElbow' -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Sınıf sayısını al\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Bulunan sınıflar ({num_classes} adet): {label_encoder.classes_}\")\n",
    "\n",
    "# Sayısal etiketleri one-hot encoding formatına çevir\n",
    "# Örn: 3 sınıf varsa, 1 -> [0, 1, 0]\n",
    "y_one_hot = to_categorical(y_encoded, num_classes=num_classes)\n",
    "\n",
    "print(f\"Veri şekli (X): {X.shape}\")\n",
    "print(f\"Etiket şekli (y): {y_one_hot.shape}\")\n",
    "print(\"Veri Dönüştürme Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 5: Eğitim ve Test Verisi Olarak Ayırma ve Ölçekleme ---\n",
    "print(\"Adım 5: Veriyi Ayırma ve Ölçekleme Başladı...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_one_hot, \n",
    "    test_size=0.2,       # Verinin %20'sini test için ayır\n",
    "    random_state=42,     # Tekrarlanabilir sonuçlar için\n",
    "    stratify=y_one_hot   # Sınıf dağılımını koru (çok önemli)\n",
    ")\n",
    "\n",
    "# Ölçekleme (Scaling) için veriyi 2D'ye çevirmemiz gerekiyor\n",
    "# (sample_sayısı, 80, 40) -> (sample_sayısı * 80, 40)\n",
    "scaler = StandardScaler()\n",
    "X_train_reshaped = X_train.reshape(-1, FEATURES)\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "X_train_scaled_reshaped = scaler.transform(X_train_reshaped)\n",
    "X_test_scaled_reshaped = scaler.transform(X_test.reshape(-1, FEATURES))\n",
    "\n",
    "# Veriyi tekrar 3D (LSTM formatı) haline getirelim\n",
    "X_train_scaled = X_train_scaled_reshaped.reshape(X_train.shape)\n",
    "X_test_scaled = X_test_scaled_reshaped.reshape(X_test.shape)\n",
    "\n",
    "print(f\"Eğitim verisi: {X_train_scaled.shape}, Test verisi: {X_test_scaled.shape}\")\n",
    "print(\"Veri Ayırma ve Ölçekleme Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 6: CNN-LSTM Modelini Oluşturma ---\n",
    "print(\"Adım 6: CNN-LSTM Hibrid Modeli Oluşturuluyor...\")\n",
    "\n",
    "model = Sequential([\n",
    "    # 1. 1D-CNN Katmanı: Zaman serisi verisinden özellik çıkarır\n",
    "    Conv1D(\n",
    "        filters=64, \n",
    "        kernel_size=3, # 3 zaman adımına aynı anda bakar\n",
    "        activation='relu', \n",
    "        input_shape=(TIMESTEPS, FEATURES)\n",
    "    ),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # 2. LSTM Katmanı: Çıkarılan özelliklerin zamansal desenini öğrenir\n",
    "    LSTM(50, return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # 3. Çıkış Katmanı\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(\"Model Oluşturma Tamamlandı.\\n\"\n",
    "\n",
    "# --- Adım 7: Modeli Eğitme ---\n",
    "print(\"Adım 7: Model Eğitimi Başlıyor...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    epochs=60, # Epoch sayısını 50-100 arası deneyebilirsin\n",
    "    batch_size=16, \n",
    "    validation_data=(X_test_scaled, y_test)\n",
    ")\n",
    "\n",
    "print(\"Model Eğitimi Tamamlandı.\\n\")\n",
    "\n",
    "\n",
    "# --- Adım 8: Modeli Değerlendirme ---\n",
    "print(\"Adım 8: Model Değerlendirmesi...\")\n",
    "\n",
    "# Test verisi üzerindeki loss ve accuracy değerleri\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Tahminleri yap\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1) # Olasılıklardan en yüksek sınıfı seç\n",
    "y_test_labels = np.argmax(y_test, axis=1) # One-hot'tan normal etikete dön\n",
    "\n",
    "# Sınıflandırma Raporu (Precision, Recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Karışıklık Matrisi (Confusion Matrix)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues', \n",
    "    xticklabels=label_encoder.classes_, \n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel('Tahmin Edilen (Predicted)')\n",
    "plt.ylabel('Gerçek (True)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Adım 9: Modeli ve Gerekli Nesneleri Kaydetme ---\n",
    "print(\"\\nAdım 9: Model ve diğer nesneler kaydediliyor...\")\n",
    "\n",
    "MODEL_OUTPUT_DIR = f\"final_lstm_models_{MOVEMENT_TYPE}\"\n",
    "if not os.path.exists(MODEL_OUTPUT_DIR):\n",
    "    os.makedirs(MODEL_OUTPUT_DIR)\n",
    "\n",
    "# 1. Keras modelini kaydet\n",
    "model.save(os.path.join(MODEL_OUTPUT_DIR, f'{MOVEMENT_TYPE}_lstm_model.h5'))\n",
    "\n",
    "# 2. Scaler'ı kaydet\n",
    "with open(os.path.join(MODEL_OUTPUT_DIR, f'{MOVEMENT_TYPE}_scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# 3. Label Encoder'ı kaydet\n",
    "with open(os.path.join(MODEL_OUTPUT_DIR, f'{MOVEMENT_TYPE}_label_encoder.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(f\"Tüm dosyalar başarıyla '{MODEL_OUTPUT_DIR}' klasörüne kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703b8e4-7238-4553-86c6-07397ec17c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adım 4: Veri Yükleme ve Ön İşleme Başladı...\n",
      "Kullanıcı yükleniyor: User-A\n",
      "Kullanıcı yükleniyor: User-B\n",
      "Kullanıcı yükleniyor: User-C\n",
      "Kullanıcı yükleniyor: User-D\n",
      "Kullanıcı yükleniyor: User-E\n",
      "Veri Yükleme Tamamlandı.\n",
      "\n",
      "Bulunan sınıflar (4 adet): ['LeaningBodyBack' 'TooHighFlexion' 'True' 'UnstableShoulder']\n",
      "\n",
      "Adım 6: LOUOCV Test Çatısı Başlatılıyor...\n",
      "\n",
      "==============================================\n",
      "MODEL TEST EDİLİYOR: CNN-LSTM\n",
      "==============================================\n",
      "\n",
      "--- Test Kullanıcısı: User-A ---\n",
      "Eğitim verisi: (720, 80, 40), Test verisi: (60, 80, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-A için Doğruluk: 53.33%\n",
      "\n",
      "--- Test Kullanıcısı: User-B ---\n",
      "Eğitim verisi: (720, 80, 40), Test verisi: (60, 80, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-B için Doğruluk: 71.67%\n",
      "\n",
      "--- Test Kullanıcısı: User-C ---\n",
      "Eğitim verisi: (720, 80, 40), Test verisi: (60, 80, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-C için Doğruluk: 46.67%\n",
      "\n",
      "--- Test Kullanıcısı: User-D ---\n",
      "Eğitim verisi: (720, 80, 40), Test verisi: (60, 80, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-D için Doğruluk: 63.33%\n",
      "\n",
      "--- Test Kullanıcısı: User-E ---\n",
      "Eğitim verisi: (720, 80, 40), Test verisi: (60, 80, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python313/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Adım 1: Gerekli Kütüphaneleri Yükleme\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy # Scaler'ı kopyalamak için\n",
    "from pyquaternion import Quaternion # Normalizasyon için\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow ve Keras kütüphanelerini import etme\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, GRU, Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n",
    "    Dense, Dropout, BatchNormalization, Input, LayerNormalization, \n",
    "    MultiHeadAttention, Add\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Flatten # <-- Ekle\n",
    "\n",
    "\n",
    "# GPU hatalarını ve gereksiz uyarıları gizle\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# --- KONFİGÜRASYON ---\n",
    "DATA_FOLDER = '' \n",
    "MOVEMENT_TYPE = '' # Test etmek istediğin hareket\n",
    "TIMESTEPS = 80 # Veri setindeki (80, 40) şekline göre\n",
    "NUM_SENSORS = 10\n",
    "FEATURES_PER_SENSOR = 4 # w, x, y, z\n",
    "FEATURES = NUM_SENSORS * FEATURES_PER_SENSOR\n",
    "USERS_TO_ANALYZE = [\"User-A\", \"User-B\", \"User-C\", \"User-D\", \"User-E\"]\n",
    "\n",
    "# Eğitim Ayarları\n",
    "EPOCHS = 100 # Overfitting'i önlemek için EarlyStopping kullanacağız\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# --- Adım 2: Yardımcı Fonksiyonlar (Veri İşleme) ---\n",
    "\n",
    "def normalize_sequence(sequence_data):\n",
    "    \"\"\"\n",
    "    (N, 40) şeklindeki bir NumPy dizisini ilk karesine göre normalize eder.\n",
    "    (w, x, y, z) sırasına göre.\n",
    "    \"\"\"\n",
    "    if not sequence_data.any(): return sequence_data\n",
    "    first_frame = sequence_data[0]\n",
    "    inverse_references = []\n",
    "    for i in range(NUM_SENSORS):\n",
    "        offset = i * FEATURES_PER_SENSOR\n",
    "        w, x, y, z = first_frame[offset:offset+4]\n",
    "        q_ref = Quaternion(w, x, y, z) if (w or x or y or z) else Quaternion(1, 0, 0, 0)\n",
    "        inverse_references.append(q_ref.inverse)\n",
    "        \n",
    "    normalized_sequence = []\n",
    "    for frame in sequence_data:\n",
    "        normalized_frame_features = []\n",
    "        for i in range(NUM_SENSORS):\n",
    "            offset = i * FEATURES_PER_SENSOR\n",
    "            w, x, y, z = frame[offset:offset+4]\n",
    "            q_live = Quaternion(w, x, y, z) if (w or x or y or z) else Quaternion(1, 0, 0, 0)\n",
    "            q_normalized = inverse_references[i] * q_live\n",
    "            normalized_frame_features.extend([q_normalized.w, q_normalized.x, q_normalized.y, q_normalized.z])\n",
    "        normalized_sequence.append(normalized_frame_features)\n",
    "    return np.array(normalized_sequence)\n",
    "\n",
    "def augment_data(sequence_data, noise_level=0.01):\n",
    "    \"\"\"Veriye rastgele küçük gürültüler (jitter) ekler.\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, sequence_data.shape)\n",
    "    return sequence_data + noise\n",
    "\n",
    "# --- Adım 3: Model Mimarilerini Oluşturan Fonksiyonlar ---\n",
    "\n",
    "INPUT_SHAPE = (TIMESTEPS, FEATURES)\n",
    "\n",
    "def build_cnn_lstm_model(num_classes):\n",
    "    \"\"\"Senin başarılı CNN-LSTM Hibrid modelin.\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"CNN_LSTM\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn_gru_model(num_classes):\n",
    "    \"\"\"LSTM yerine GRU kullanan, daha hızlı ve daha az veriye ihtiyaç duyan model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        GRU(50, return_sequences=False), # <-- DEĞİŞİKLİK\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"CNN_GRU\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn_ann_model(num_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(), # <-- GlobalAveragePooling yerine Flatten\n",
    "        \n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"CNN_ANN_Hybrid\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_pure_cnn_model(num_classes):\n",
    "    \"\"\"Sadece 1D-CNN katmanları kullanan model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling1D(), # <-- LSTM/GRU yerine\n",
    "        \n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"Pure_1D_CNN\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_transformer_model(num_classes):\n",
    "    \"\"\"Basit bir Transformer Encoder bloğu kullanan model.\"\"\"\n",
    "    inputs = Input(shape=INPUT_SHAPE)\n",
    "    \n",
    "    # 1. Önce CNN ile özellikleri çıkaralım (Transformer'a yardımcı olur)\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # --- Transformer Encoder Bloğu ---\n",
    "    # 2. Multi-Head Attention\n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    attn_output = Dropout(0.2)(attn_output)\n",
    "    x = Add()([x, attn_output]) # Residual Connection (Toplama)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    # 3. Feed Forward Kısmı\n",
    "    ff_output = Dense(128, activation='relu')(x)\n",
    "    ff_output = Dropout(0.2)(ff_output)\n",
    "    ff_output = Dense(64, activation='relu')(ff_output)\n",
    "    x = Add()([x, ff_output]) # Residual Connection\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    # --- Blok Sonu ---\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Transformer\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Adım 4: Veriyi Yükleme ve Ön İşleme ---\n",
    "print(\"Adım 4: Veri Yükleme ve Ön İşleme Başladı...\")\n",
    "data_by_user = {}\n",
    "all_labels_flat = []\n",
    "\n",
    "movement_path = os.path.join(DATA_FOLDER, MOVEMENT_TYPE)\n",
    "for user_folder in USERS_TO_ANALYZE:\n",
    "    user_path = os.path.join(movement_path, user_folder)\n",
    "    if not os.path.isdir(user_path):\n",
    "        print(f\"Uyarı: Kullanıcı klasörü atlanıyor (bulunamadı): {user_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Kullanıcı yükleniyor: {user_folder}\")\n",
    "    data_by_user[user_folder] = {'data': [], 'labels': []}\n",
    "    \n",
    "    for label_folder in os.listdir(user_path):\n",
    "        label_path = os.path.join(user_path, label_folder)\n",
    "        if os.path.isdir(label_path):\n",
    "            for pkl_file in os.listdir(label_path):\n",
    "                if pkl_file.endswith('.pkl'):\n",
    "                    file_path = os.path.join(label_path, pkl_file)\n",
    "                    try:\n",
    "                        with open(file_path, 'rb') as f:\n",
    "                            obj = pickle.load(f)\n",
    "                        recording_data = np.array(obj['data'])\n",
    "                        if recording_data.shape[0] < 1 or recording_data.shape[1] != FEATURES:\n",
    "                            continue\n",
    "                        \n",
    "                        # --- Normalizasyon ve Boyut Eşitleme ---\n",
    "                        recording_data_normalized = normalize_sequence(recording_data)\n",
    "                        recording_data_padded = pad_sequences(\n",
    "                            [recording_data_normalized], maxlen=TIMESTEPS, dtype='float32', \n",
    "                            padding='post', truncating='post'\n",
    "                        )[0] # [0] ile (1, 80, 40) yerine (80, 40) al\n",
    "                        \n",
    "                        data_by_user[user_folder]['data'].append(recording_data_padded)\n",
    "                        data_by_user[user_folder]['labels'].append(label_folder)\n",
    "                        all_labels_flat.append(label_folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Hata: {file_path} dosyası okunurken hata oluştu: {e}\")\n",
    "\n",
    "print(\"Veri Yükleme Tamamlandı.\\n\")\n",
    "\n",
    "# --- Adım 5: Etiket Kodlayıcıyı Hazırlama ---\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels_flat)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Bulunan sınıflar ({num_classes} adet): {label_encoder.classes_}\\n\")\n",
    "\n",
    "# --- Adım 6: LOUOCV Test Çatısı ---\n",
    "print(\"Adım 6: LOUOCV Test Çatısı Başlatılıyor...\")\n",
    "\n",
    "# Test edilecek modelleri ve oluşturma fonksiyonlarını bir sözlükte topla\n",
    "models_to_test = {\n",
    "    \"CNN-LSTM\": build_cnn_lstm_model,\n",
    "    #\"Pure 1D-CNN\": build_pure_cnn_model,\n",
    "    #\"Transformer\": build_transformer_model,\n",
    "    #\"ANN\": build_cnn_ann_model\n",
    "}\n",
    "\n",
    "# Sonuçları saklamak için\n",
    "overall_results = {}\n",
    "all_classification_reports = {}\n",
    "\n",
    "# Aşırı öğrenmeyi engellemek için Erken Durdurma\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Her bir model için döngü\n",
    "for model_name, build_fn in models_to_test.items():\n",
    "    print(f\"\\n==============================================\")\n",
    "    print(f\"MODEL TEST EDİLİYOR: {model_name}\")\n",
    "    print(f\"==============================================\")\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    # LOUOCV döngüsü (her kullanıcı için)\n",
    "    for user_to_test in USERS_TO_ANALYZE:\n",
    "        print(f\"\\n--- Test Kullanıcısı: {user_to_test} ---\")\n",
    "        \n",
    "        # 1. Eğitim ve Test Verisini Ayır\n",
    "        X_train_list, y_train_list = [], []\n",
    "        X_test_list, y_test_list = [], []\n",
    "\n",
    "        for user, data in data_by_user.items():\n",
    "            if user == user_to_test:\n",
    "                X_test_list.extend(data['data'])\n",
    "                y_test_list.extend(data['labels'])\n",
    "            else:\n",
    "                X_train_list.extend(data['data'])\n",
    "                y_train_list.extend(data['labels'])\n",
    "\n",
    "        # 2. Veri Artırma (Sadece Eğitim Verisine)\n",
    "        X_train_aug, y_train_aug = [], []\n",
    "        for i in range(len(X_train_list)):\n",
    "            seq, lbl = X_train_list[i], y_train_list[i]\n",
    "            X_train_aug.append(seq) # Orijinal\n",
    "            y_train_aug.append(lbl)\n",
    "            X_train_aug.append(augment_data(seq, 0.01)) # Gürültülü 1\n",
    "            y_train_aug.append(lbl)\n",
    "            X_train_aug.append(augment_data(seq, 0.005)) # Gürültülü 2\n",
    "            y_train_aug.append(lbl)\n",
    "\n",
    "        X_train = np.array(X_train_aug)\n",
    "        X_test = np.array(X_test_list)\n",
    "        \n",
    "        # 3. Etiketleri Kodla\n",
    "        y_train = to_categorical(label_encoder.transform(y_train_aug), num_classes=num_classes)\n",
    "        y_test = to_categorical(label_encoder.transform(y_test_list), num_classes=num_classes)\n",
    "\n",
    "        # 4. Ölçekle (Scaler'ı SADECE artırılmış eğitim verisine göre eğit)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_reshaped = X_train.reshape(-1, FEATURES)\n",
    "        scaler.fit(X_train_reshaped)\n",
    "        \n",
    "        X_train_scaled = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "        X_test_scaled = scaler.transform(X_test.reshape(-1, FEATURES)).reshape(X_test.shape)\n",
    "        \n",
    "        print(f\"Eğitim verisi: {X_train_scaled.shape}, Test verisi: {X_test_scaled.shape}\")\n",
    "\n",
    "        # 5. Modeli Oluştur ve Eğit\n",
    "        model = build_fn(num_classes)\n",
    "        model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_test_scaled, y_test),\n",
    "            callbacks=[early_stopping], # Erken durdurmayı kullan\n",
    "            verbose=0 # Logları gizle\n",
    "        )\n",
    "        \n",
    "        # 6. Değerlendir\n",
    "        loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        fold_scores.append(accuracy)\n",
    "        print(f\"{user_to_test} için Doğruluk: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Modelin ortalama LOUOCV skorunu kaydet\n",
    "    overall_results[model_name] = np.mean(fold_scores)\n",
    "\n",
    "\n",
    "# --- Adım 7: Nihai Sonuçları Göster ---\n",
    "print(\"\\n\\n==============================================\")\n",
    "print(\"     LOUOCV GENEL SONUÇLARI     \")\n",
    "print(\"==============================================\")\n",
    "print(f\"Test Edilen Hareket: {MOVEMENT_TYPE}\")\n",
    "print(f\"Veri Seti: {len(USERS_TO_ANALYZE)} Kullanıcı, Toplam {len(all_labels_flat)} Orijinal Kayıt\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "for model_name, avg_accuracy in overall_results.items():\n",
    "    print(f\"Model: {model_name.ljust(12)} | Ortalama Genelleme Doğruluğu: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d04c19-8743-4c10-8a5e-d948d3e479fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 1: Gerekli Kütüphaneleri Yükleme\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pyquaternion import Quaternion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, GRU, Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n",
    "    Dense, Dropout, BatchNormalization, Input, LayerNormalization, \n",
    "    MultiHeadAttention, Add\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Flatten # <-- Ekle\n",
    "# Gereksiz TensorFlow ve Keras uyarılarını gizle\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "tf.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings('ignore', category=UserWarning) # Keras uyarılarını gizle\n",
    "\n",
    "# --- KONFİGÜRASYON ---\n",
    "DATA_FOLDER = '' \n",
    "MOVEMENT_TYPE = ''\n",
    "TIMESTEPS = 80\n",
    "NUM_SENSORS = 10\n",
    "FEATURES_PER_SENSOR = 4 # w, x, y, z\n",
    "FEATURES = NUM_SENSORS * FEATURES_PER_SENSOR\n",
    "USERS_TO_ANALYZE = [\"User-A\", \"User-B\", \"User-C\", \"User-D\", \"User-E\"]\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# --- Adım 2: Yardımcı Fonksiyonlar ---\n",
    "\n",
    "def normalize_sequence(sequence_data):\n",
    "    \"\"\"(N, 40) veriyi ilk karesine göre normalize eder.\"\"\"\n",
    "    if not sequence_data.any(): return sequence_data\n",
    "    first_frame = sequence_data[0]\n",
    "    inverse_references = []\n",
    "    for i in range(NUM_SENSORS):\n",
    "        offset = i * FEATURES_PER_SENSOR\n",
    "        w, x, y, z = first_frame[offset:offset+4]\n",
    "        q_ref = Quaternion(w, x, y, z) if (w or x or y or z) else Quaternion(1, 0, 0, 0)\n",
    "        inverse_references.append(q_ref.inverse)\n",
    "        \n",
    "    normalized_sequence = []\n",
    "    for frame in sequence_data:\n",
    "        normalized_frame_features = []\n",
    "        for i in range(NUM_SENSORS):\n",
    "            offset = i * FEATURES_PER_SENSOR\n",
    "            w, x, y, z = frame[offset:offset+4]\n",
    "            q_live = Quaternion(w, x, y, z) if (w or x or y or z) else Quaternion(1, 0, 0, 0)\n",
    "            q_normalized = inverse_references[i] * q_live\n",
    "            normalized_frame_features.extend([q_normalized.w, q_normalized.x, q_normalized.y, q_normalized.z])\n",
    "        normalized_sequence.append(normalized_frame_features)\n",
    "    return np.array(normalized_sequence)\n",
    "\n",
    "# --- Adım 3: Model Mimarilerini Oluşturan Fonksiyonlar ---\n",
    "INPUT_SHAPE = (TIMESTEPS, FEATURES)\n",
    "\n",
    "def build_cnn_lstm_model(num_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"CNN_LSTM\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn_gru_model(num_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        GRU(50, return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"CNN_GRU\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn_ann_model(num_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(), # <-- GlobalAveragePooling yerine Flatten\n",
    "        \n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"CNN_ANN_Hybrid\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "def build_pure_cnn_model(num_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=\"Pure_1D_CNN\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_transformer_model(num_classes):\n",
    "    inputs = Input(shape=INPUT_SHAPE)\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    attn_output = Dropout(0.2)(attn_output)\n",
    "    x = Add()([x, attn_output])\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    ff_output = Dense(128, activation='relu')(x)\n",
    "    ff_output = Dropout(0.2)(ff_output)\n",
    "    ff_output = Dense(64, activation='relu')(ff_output)\n",
    "    x = Add()([x, ff_output])\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Transformer\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- Adım 4: Veriyi Yükleme, İşleme ve Ayırma ---\n",
    "print(\"Adım 4: Veri Yükleniyor ve İşleniyor...\")\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "movement_path = os.path.join(DATA_FOLDER, MOVEMENT_TYPE)\n",
    "\n",
    "for user_folder in USERS_TO_ANALYZE:\n",
    "    user_path = os.path.join(movement_path, user_folder)\n",
    "    if not os.path.isdir(user_path): continue\n",
    "    for label_folder in os.listdir(user_path):\n",
    "        label_path = os.path.join(user_path, label_folder)\n",
    "        if os.path.isdir(label_path):\n",
    "            for pkl_file in os.listdir(label_path):\n",
    "                if pkl_file.endswith('.pkl'):\n",
    "                    file_path = os.path.join(label_path, pkl_file)\n",
    "                    try:\n",
    "                        with open(file_path, 'rb') as f: obj = pickle.load(f)\n",
    "                        recording_data = np.array(obj['data'])\n",
    "                        if recording_data.shape[0] < 1 or recording_data.shape[1] != FEATURES: continue\n",
    "                        \n",
    "                        recording_data_normalized = normalize_sequence(recording_data)\n",
    "                        recording_data_padded = pad_sequences(\n",
    "                            [recording_data_normalized], maxlen=TIMESTEPS, dtype='float32', \n",
    "                            padding='post', truncating='post'\n",
    "                        )[0]\n",
    "                        \n",
    "                        all_data.append(recording_data_padded)\n",
    "                        all_labels.append(label_folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Hata: {file_path} dosyası okunurken hata oluştu: {e}\")\n",
    "\n",
    "print(f\"Toplam {len(all_data)} adet orijinal .pkl kaydı yüklendi.\")\n",
    "\n",
    "# Etiketleri Kodla\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(all_labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_one_hot = to_categorical(y_encoded, num_classes=num_classes)\n",
    "X = np.array(all_data)\n",
    "\n",
    "print(f\"Bulunan sınıflar: {label_encoder.classes_}\")\n",
    "\n",
    "# Veriyi Rastgele Ayır (LOUOCV OLMADAN)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_one_hot, \n",
    "    test_size=0.2, # 300 kaydın %20'si = 60 test kaydı\n",
    "    random_state=42, \n",
    "    stratify=y_one_hot # Sınıf dağılımını koru\n",
    ")\n",
    "\n",
    "# Ölçekle\n",
    "scaler = StandardScaler()\n",
    "X_train_reshaped = X_train.reshape(-1, FEATURES)\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, FEATURES)).reshape(X_test.shape)\n",
    "\n",
    "print(f\"Eğitim verisi: {X_train_scaled.shape}, Test verisi: {X_test_scaled.shape}\")\n",
    "print(\"Veri Ayırma ve Ölçekleme Tamamlandı.\\n\")\n",
    "\n",
    "# --- Adım 5: Modelleri Karşılaştırmalı Olarak Eğitme ve Değerlendirme ---\n",
    "print(\"Adım 5: Karşılaştırmalı Model Testi Başlatılıyor...\")\n",
    "\n",
    "models_to_test = {\n",
    "    \"CNN-LSTM\": build_cnn_lstm_model,\n",
    "    \"Pure 1D-CNN\": build_pure_cnn_model,\n",
    "    #\"Transformer\": build_transformer_model,\n",
    "    \"ANN\": build_cnn_ann_model,\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "results = {}\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "for model_name, build_fn in models_to_test.items():\n",
    "    print(f\"\\n--- Model Eğitiliyor: {model_name} ---\")\n",
    "    model = build_fn(num_classes)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0 # Logları gizle\n",
    "    )\n",
    "    \n",
    "    # Değerlendir\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(f\"Test Doğruluğu: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    y_pred_probs = model.predict(X_test_scaled)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_labels, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    results[model_name] = accuracy\n",
    "\n",
    "# --- Adım 6: Nihai Sonuçları Göster ---\n",
    "print(\"\\n\\n==============================================\")\n",
    "print(\"     RASTGELE BÖLME (Mixed-User) TEST SONUÇLARI     \")\n",
    "print(\"==============================================\")\n",
    "print(f\"Test Edilen Hareket: {MOVEMENT_TYPE}\")\n",
    "print(f\"Veri Seti: {len(USERS_TO_ANALYZE)} Kullanıcı, Toplam {len(all_labels)} Orijinal Kayıt\")\n",
    "print(\"Veri Artırma: KULLANILMADI\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "for model_name, avg_accuracy in results.items():\n",
    "    print(f\"Model: {model_name.ljust(12)} | Kişiselleştirilmiş Doğruluk: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78d072-e5c3-4aa6-8370-75e0ca5c8ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 06:20:47.409161: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-10 06:20:47.409576: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-10 06:20:47.477540: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-10 06:20:48.770896: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-10 06:20:48.772623: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adım 4: Veri Yükleme ve Ön İşleme Başladı...\n",
      "HATA: Hareket klasörü bulunamadı: \n",
      "Lütfen DATA_FOLDER ve MOVEMENT_TYPE değişkenlerini kontrol edin.\n",
      "Kullanıcı yükleniyor: User-A\n",
      "Kullanıcı yükleniyor: User-B\n",
      "Kullanıcı yükleniyor: User-C\n",
      "Kullanıcı yükleniyor: User-D\n",
      "Kullanıcı yükleniyor: User-E\n",
      "Veri Yükleme Tamamlandı.\n",
      "\n",
      "Bulunan sınıflar (4 adet): ['LeaningBodyBack' 'TooHighFlexion' 'True' 'UnstableShoulder']\n",
      "\n",
      "Adım 6: LOUOCV Test Çatısı Başlatılıyor...\n",
      "\n",
      "==============================================\n",
      "MODEL TEST EDİLİYOR: Transformer\n",
      "==============================================\n",
      "\n",
      "--- Test Kullanıcısı: User-A ---\n",
      "Eğitim verisi: (720, 80, 40), Test verisi: (60, 80, 40)\n"
     ]
    }
   ],
   "source": [
    "# Adım 1: Gerekli Kütüphaneleri Yükleme\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy \n",
    "from pyquaternion import Quaternion\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow ve Keras kütüphanelerini import etme\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n",
    "    Dense, Dropout, BatchNormalization, Input, LayerNormalization, \n",
    "    MultiHeadAttention, Add, Flatten\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# GPU hatalarını ve gereksiz uyarıları gizle\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# --- KONFİGÜRASYON ---\n",
    "# LÜTFEN BUNLARI KENDİ VERİ YOLUNUZA GÖRE DÜZENLEYİN:\n",
    "DATA_FOLDER = ''  \n",
    "MOVEMENT_TYPE = '' # Test etmek istediğin hareket\n",
    "TIMESTEPS = 80 # Veri setindeki (80, 40) şekline göre\n",
    "NUM_SENSORS = 10\n",
    "FEATURES_PER_SENSOR = 4 # w, x, y, z\n",
    "FEATURES = NUM_SENSORS * FEATURES_PER_SENSOR\n",
    "USERS_TO_ANALYZE = [\"User-A\", \"User-B\", \"User-C\", \"User-D\", \"User-E\"]\n",
    "\n",
    "# Eğitim Ayarları\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "INPUT_SHAPE = (TIMESTEPS, FEATURES)\n",
    "\n",
    "# --- Adım 1.5: Görselleştirme Fonksiyonu ---\n",
    "\n",
    "def plot_confusion_matrix(y_true_labels, y_pred_labels, class_names, title, save_path=None):\n",
    "    \"\"\"Confusion Matrix'i çizer ve kaydeder.\"\"\"\n",
    "    # Matrisi oluştur\n",
    "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "    # Satır bazında normalize et (Her sınıfın ne kadar doğru tahmin edildiğini gösterir)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] \n",
    "\n",
    "    # Görselleştirme\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm_normalized,\n",
    "        annot=True,\n",
    "        fmt=\".2f\", # 2 ondalık basamaklı format\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names\n",
    "    )\n",
    "    plt.title(f\"Normalized Confusion Matrix: {title}\")\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion Matrix {save_path} adresine kaydedildi.\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Adım 2: Yardımcı Fonksiyonlar (Veri İşleme) ---\n",
    "\n",
    "def normalize_sequence(sequence_data):\n",
    "    \"\"\"\n",
    "    (N, 40) şeklindeki bir NumPy dizisini ilk karesine göre normalize eder.\n",
    "    (w, x, y, z) sırasına göre.\n",
    "    \"\"\"\n",
    "    if not sequence_data.any(): return sequence_data\n",
    "    first_frame = sequence_data[0]\n",
    "    inverse_references = []\n",
    "    for i in range(NUM_SENSORS):\n",
    "        offset = i * FEATURES_PER_SENSOR\n",
    "        w, x, y, z = first_frame[offset:offset+4]\n",
    "        q_ref = Quaternion(w, x, y, z) if (w or x or y or z) else Quaternion(1, 0, 0, 0)\n",
    "        inverse_references.append(q_ref.inverse)\n",
    "        \n",
    "    normalized_sequence = []\n",
    "    for frame in sequence_data:\n",
    "        normalized_frame_features = []\n",
    "        for i in range(NUM_SENSORS):\n",
    "            offset = i * FEATURES_PER_SENSOR\n",
    "            w, x, y, z = frame[offset:offset+4]\n",
    "            q_live = Quaternion(w, x, y, z) if (w or x or y or z) else Quaternion(1, 0, 0, 0)\n",
    "            q_normalized = inverse_references[i] * q_live\n",
    "            normalized_frame_features.extend([q_normalized.w, q_normalized.x, q_normalized.y, q_normalized.z])\n",
    "        normalized_sequence.append(normalized_frame_features)\n",
    "    return np.array(normalized_sequence)\n",
    "\n",
    "def augment_data(sequence_data, noise_level=0.01):\n",
    "    \"\"\"Veriye rastgele küçük gürültüler (jitter) ekler.\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, sequence_data.shape)\n",
    "    return sequence_data + noise\n",
    "\n",
    "# --- Adım 3: Model Mimarilerini Oluşturan Fonksiyonlar ---\n",
    "# Sadece Transformer modelini bırakıyorum. Diğer modelleri isterseniz ekleyebilirsiniz.\n",
    "\n",
    "def build_transformer_model(num_classes):\n",
    "    \"\"\"Basit bir Transformer Encoder bloğu kullanan model.\"\"\"\n",
    "    inputs = Input(shape=INPUT_SHAPE)\n",
    "    \n",
    "    # 1. Önce CNN ile özellikleri çıkaralım\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # --- Transformer Encoder Bloğu ---\n",
    "    # 2. Multi-Head Attention\n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    attn_output = Dropout(0.2)(attn_output)\n",
    "    x = Add()([x, attn_output])\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    # 3. Feed Forward Kısmı\n",
    "    ff_output = Dense(128, activation='relu')(x)\n",
    "    ff_output = Dropout(0.2)(ff_output)\n",
    "    ff_output = Dense(64, activation='relu')(ff_output)\n",
    "    x = Add()([x, ff_output])\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    # --- Blok Sonu ---\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Transformer\")\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Adım 4: Veriyi Yükleme ve Ön İşleme ---\n",
    "print(\"Adım 4: Veri Yükleme ve Ön İşleme Başladı...\")\n",
    "data_by_user = {}\n",
    "all_labels_flat = []\n",
    "\n",
    "movement_path = os.path.join(DATA_FOLDER, MOVEMENT_TYPE)\n",
    "if not os.path.isdir(movement_path):\n",
    "    print(f\"HATA: Hareket klasörü bulunamadı: {movement_path}\")\n",
    "    print(\"Lütfen DATA_FOLDER ve MOVEMENT_TYPE değişkenlerini kontrol edin.\")\n",
    "    exit()\n",
    "\n",
    "for user_folder in USERS_TO_ANALYZE:\n",
    "    user_path = os.path.join(movement_path, user_folder)\n",
    "    if not os.path.isdir(user_path):\n",
    "        print(f\"Uyarı: Kullanıcı klasörü atlanıyor (bulunamadı): {user_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Kullanıcı yükleniyor: {user_folder}\")\n",
    "    data_by_user[user_folder] = {'data': [], 'labels': []}\n",
    "    \n",
    "    for label_folder in os.listdir(user_path):\n",
    "        label_path = os.path.join(user_path, label_folder)\n",
    "        if os.path.isdir(label_path):\n",
    "            for pkl_file in os.listdir(label_path):\n",
    "                if pkl_file.endswith('.pkl'):\n",
    "                    file_path = os.path.join(label_path, pkl_file)\n",
    "                    try:\n",
    "                        with open(file_path, 'rb') as f:\n",
    "                            obj = pickle.load(f)\n",
    "                        recording_data = np.array(obj['data'])\n",
    "                        if recording_data.shape[0] < 1 or recording_data.shape[1] != FEATURES:\n",
    "                            continue\n",
    "                        \n",
    "                        # --- Normalizasyon ve Boyut Eşitleme ---\n",
    "                        recording_data_normalized = normalize_sequence(recording_data)\n",
    "                        recording_data_padded = pad_sequences(\n",
    "                            [recording_data_normalized], maxlen=TIMESTEPS, dtype='float32', \n",
    "                            padding='post', truncating='post'\n",
    "                        )[0]\n",
    "                        \n",
    "                        data_by_user[user_folder]['data'].append(recording_data_padded)\n",
    "                        data_by_user[user_folder]['labels'].append(label_folder)\n",
    "                        all_labels_flat.append(label_folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Hata: {file_path} dosyası okunurken hata oluştu: {e}\")\n",
    "\n",
    "print(\"Veri Yükleme Tamamlandı.\\n\")\n",
    "\n",
    "# --- Adım 5: Etiket Kodlayıcıyı Hazırlama ---\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels_flat)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "print(f\"Bulunan sınıflar ({num_classes} adet): {class_names}\\n\")\n",
    "\n",
    "# --- Adım 6: LOUOCV Test Çatısı ---\n",
    "print(\"Adım 6: LOUOCV Test Çatısı Başlatılıyor...\")\n",
    "\n",
    "models_to_test = {\n",
    "    \"Transformer\": build_transformer_model,\n",
    "}\n",
    "\n",
    "overall_results = {}\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Her bir model için döngü\n",
    "for model_name, build_fn in models_to_test.items():\n",
    "    print(f\"\\n==============================================\")\n",
    "    print(f\"MODEL TEST EDİLİYOR: {model_name}\")\n",
    "    print(f\"==============================================\")\n",
    "    \n",
    "    fold_scores = []\n",
    "    # Confusion Matrix için tahminleri ve gerçek etiketleri toplamak için\n",
    "    all_y_test_true = []\n",
    "    all_y_test_pred = []\n",
    "    \n",
    "    # LOUOCV döngüsü (her kullanıcı için)\n",
    "    for user_to_test in USERS_TO_ANALYZE:\n",
    "        print(f\"\\n--- Test Kullanıcısı: {user_to_test} ---\")\n",
    "        \n",
    "        # 1. Eğitim ve Test Verisini Ayır\n",
    "        X_train_list, y_train_list = [], []\n",
    "        X_test_list, y_test_list = [], []\n",
    "\n",
    "        for user, data in data_by_user.items():\n",
    "            if user == user_to_test:\n",
    "                X_test_list.extend(data['data'])\n",
    "                y_test_list.extend(data['labels'])\n",
    "            else:\n",
    "                X_train_list.extend(data['data'])\n",
    "                y_train_list.extend(data['labels'])\n",
    "\n",
    "        # 2. Veri Artırma (Sadece Eğitim Verisine)\n",
    "        X_train_aug, y_train_aug = [], []\n",
    "        for i in range(len(X_train_list)):\n",
    "            seq, lbl = X_train_list[i], y_train_list[i]\n",
    "            X_train_aug.append(seq) # Orijinal\n",
    "            y_train_aug.append(lbl)\n",
    "            X_train_aug.append(augment_data(seq, 0.01)) # Gürültülü 1\n",
    "            y_train_aug.append(lbl)\n",
    "            X_train_aug.append(augment_data(seq, 0.005)) # Gürültülü 2\n",
    "            y_train_aug.append(lbl)\n",
    "\n",
    "        X_train = np.array(X_train_aug)\n",
    "        X_test = np.array(X_test_list)\n",
    "        \n",
    "        # 3. Etiketleri Kodla\n",
    "        y_train = to_categorical(label_encoder.transform(y_train_aug), num_classes=num_classes)\n",
    "        y_test = to_categorical(label_encoder.transform(y_test_list), num_classes=num_classes)\n",
    "\n",
    "        # 4. Ölçekle (Scaler'ı SADECE artırılmış eğitim verisine göre eğit)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_reshaped = X_train.reshape(-1, FEATURES)\n",
    "        scaler.fit(X_train_reshaped)\n",
    "        \n",
    "        X_train_scaled = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "        X_test_scaled = scaler.transform(X_test.reshape(-1, FEATURES)).reshape(X_test.shape)\n",
    "        \n",
    "        print(f\"Eğitim verisi: {X_train_scaled.shape}, Test verisi: {X_test_scaled.shape}\")\n",
    "\n",
    "        # 5. Modeli Oluştur ve Eğit\n",
    "        model = build_fn(num_classes)\n",
    "        model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_test_scaled, y_test),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # 6. Değerlendir\n",
    "        loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        fold_scores.append(accuracy)\n",
    "        print(f\"{user_to_test} için Doğruluk: {accuracy * 100:.2f}%\")\n",
    "\n",
    "        # --- TAHMİNLERİ TOPLAMA KISMI ---\n",
    "        y_pred_proba = model.predict(X_test_scaled, verbose=0)\n",
    "        y_pred_fold = np.argmax(y_pred_proba, axis=1) # Tahmin edilen sınıf indeksi\n",
    "        y_true_fold = np.argmax(y_test, axis=1)      # Gerçek sınıf indeksi\n",
    "        \n",
    "        # Etiketleri metin formatına geri çevir\n",
    "        y_true_labels = label_encoder.inverse_transform(y_true_fold)\n",
    "        y_pred_labels = label_encoder.inverse_transform(y_pred_fold)\n",
    "\n",
    "        all_y_test_true.extend(y_true_labels)\n",
    "        all_y_test_pred.extend(y_pred_labels)\n",
    "        \n",
    "    # Modelin ortalama LOUOCV skorunu kaydet\n",
    "    overall_results[model_name] = np.mean(fold_scores)\n",
    "\n",
    "    # --- CONFUSION MATRIX ÇİZİMİ ---\n",
    "    plot_confusion_matrix(\n",
    "        y_true_labels=all_y_test_true,\n",
    "        y_pred_labels=all_y_test_pred,\n",
    "        class_names=class_names,\n",
    "        title=f\"{model_name} LOUOCV Generalization ({MOVEMENT_TYPE})\",\n",
    "        save_path=f\"{MOVEMENT_TYPE}_{model_name}_CM.png\"\n",
    "    )\n",
    "\n",
    "# --- Adım 7: Nihai Sonuçları Göster ---\n",
    "print(\"\\n\\n==============================================\")\n",
    "print(\"     LOUOCV GENEL SONUÇLARI     \")\n",
    "print(\"==============================================\")\n",
    "print(f\"Test Edilen Hareket: {MOVEMENT_TYPE}\")\n",
    "print(f\"Veri Seti: {len(USERS_TO_ANALYZE)} Kullanıcı, Toplam {len(all_labels_flat)} Orijinal Kayıt\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "for model_name, avg_accuracy in overall_results.items():\n",
    "    print(f\"Model: {model_name.ljust(12)} | Ortalama Genelleme Doğruluğu: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5657fc-70d7-423c-a629-1bac319a135b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
